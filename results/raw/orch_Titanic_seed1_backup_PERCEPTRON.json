{
  "method_name": "Perceptron",
  "best_fitness": 0.576271186440678,
  "best_solution": {
    "w": [
      -0.015584006513488237,
      0.03616332179012624,
      -0.056317783598360246,
      -0.04775624244586314,
      0.012644363655406481,
      0.058653989946372984,
      0.010890139405395363,
      -9.678087071047017e-05,
      -0.007012697987430061
    ],
    "b": 0.020000000000000004
  },
  "history": [
    0.5871559633027523,
    0.5072463768115941,
    0.6470588235294117,
    0.6857142857142857,
    0.6,
    0.6792452830188679,
    0.4952380952380952,
    0.717948717948718,
    0.7079646017699115,
    0.5742574257425742,
    0.6095238095238096,
    0.7142857142857142,
    0.6714285714285714,
    0.7339449541284403,
    0.6407766990291263,
    0.7741935483870969,
    0.4954128440366973,
    0.7540983606557377,
    0.5050505050505051,
    0.7301587301587302,
    0.5660377358490566,
    0.717948717948718,
    0.5132743362831859,
    0.7652173913043478,
    0.7130434782608696,
    0.7479674796747968,
    0.4719101123595506,
    0.6666666666666666,
    0.6666666666666665,
    0.6666666666666666,
    0.6434782608695652,
    0.5263157894736842,
    0.6336633663366336,
    0.5957446808510638,
    0.6942148760330578,
    0.594059405940594,
    0.5494505494505494,
    0.7317073170731706,
    0.6542056074766355,
    0.6825396825396826,
    0.514851485148515,
    0.7401574803149608,
    0.6141732283464567,
    0.6238532110091742,
    0.5892857142857143,
    0.6140350877192983,
    0.6306306306306307,
    0.5739130434782609,
    0.6909090909090909,
    0.5625000000000001,
    0.6554621848739496,
    0.6071428571428571,
    0.717948717948718,
    0.6846846846846847,
    0.2222222222222222,
    0.6355140186915887,
    0.7031250000000001,
    0.6942148760330578,
    0.6363636363636365,
    0.5652173913043479,
    0.4492753623188406,
    0.4285714285714285,
    0.553191489361702,
    0.7027027027027027,
    0.5057471264367815,
    0.6721311475409835,
    0.7,
    0.6666666666666666,
    0.6306306306306307,
    0.6666666666666666,
    0.6504065040650407,
    0.5066666666666666,
    0.6727272727272727,
    0.6851851851851851,
    0.6942148760330578,
    0.6779661016949153,
    0.5981308411214953,
    0.631578947368421,
    0.6346153846153847,
    0.768,
    0.6055045871559633,
    0.6923076923076923,
    0.746031746031746,
    0.5890410958904109,
    0.7027027027027027,
    0.66,
    0.62,
    0.5684210526315789,
    0.5050505050505051,
    0.7017543859649122,
    0.45161290322580644,
    0.6545454545454547,
    0.7413793103448276,
    0.6666666666666665,
    0.7155963302752293,
    0.7851851851851853,
    0.696969696969697,
    0.768,
    0.6833333333333333,
    0.7304347826086957,
    0.7559055118110236,
    0.75,
    0.7192982456140351,
    0.7007299270072993,
    0.6346153846153847,
    0.58,
    0.6434782608695652,
    0.5416666666666666,
    0.5606060606060607,
    0.6262626262626263,
    0.7678571428571429,
    0.6923076923076923,
    0.7142857142857142,
    0.6534653465346535,
    0.7304347826086957,
    0.6666666666666666,
    0.6274509803921569,
    0.7636363636363636,
    0.5657894736842105,
    0.6542056074766355,
    0.7222222222222223,
    0.6122448979591837,
    0.4651162790697674,
    0.6857142857142857,
    0.5631067961165049,
    0.6407766990291263,
    0.5945945945945946,
    0.784,
    0.4675324675324675,
    0.6185567010309277,
    0.6481481481481481,
    0.6534653465346535,
    0.7131782945736433,
    0.577319587628866,
    0.4592592592592593,
    0.7652173913043478,
    0.6964285714285715,
    0.6727272727272727,
    0.6666666666666666,
    0.6415094339622641,
    0.7874015748031497,
    0.6796116504854369,
    0.7833333333333333,
    0.6446280991735538,
    0.7226890756302521,
    0.6238532110091742,
    0.32142857142857145,
    0.728813559322034,
    0.7413793103448276,
    0.6226415094339623,
    0.5,
    0.5945945945945946,
    0.691588785046729,
    0.6607142857142857,
    0.7272727272727272,
    0.574468085106383,
    0.7457627118644068,
    0.6972477064220183,
    0.7563025210084034,
    0.7226890756302521,
    0.6346153846153847,
    0.5737704918032787,
    0.6666666666666665,
    0.4395604395604395,
    0.7079646017699115,
    0.6666666666666667,
    0.752,
    0.7323943661971831,
    0.5555555555555556,
    0.6476190476190475,
    0.5547445255474452,
    0.6153846153846153,
    0.17910447761194032,
    0.607843137254902,
    0.691588785046729,
    0.6557377049180327,
    0.5967741935483871,
    0.5979381443298969,
    0.7027027027027027,
    0.4444444444444444,
    0.6415094339622641,
    0.6909090909090909,
    0.5531914893617021,
    0.6138613861386139,
    0.6601941747572816,
    0.6942148760330578,
    0.6972477064220183,
    0.577319587628866,
    0.6610169491525424,
    0.717557251908397,
    0.5673758865248227,
    0.5918367346938777,
    0.7580645161290323,
    0.6271186440677966,
    0.5233644859813084,
    0.6548672566371682,
    0.6833333333333333,
    0.5591397849462365,
    0.5,
    0.6126126126126126
  ],
  "metrics": {
    "test_accuracy": 0.6296296296296297,
    "test_precision": 0.4927536231884058,
    "test_recall": 0.6938775510204082,
    "test_f1": 0.576271186440678,
    "val_best_f1": 0.7874015748031497
  },
  "time_sec": 0.24543046951293945,
  "iterations": 200,
  "status": "ok",
  "params_used": {
    "learning_rate": 0.01,
    "epochs": 200,
    "l2": 0.0,
    "threshold": 0.5
  },
  "message": null,
  "extra": {
    "problem_type": "classification",
    "task": "Titanic survival prediction",
    "target": "Survived (0/1)",
    "features": [
      "Pclass",
      "Sex",
      "Age",
      "SibSp",
      "Parch",
      "Fare",
      "Embarked_C",
      "Embarked_Q",
      "Embarked_S"
    ],
    "preprocessing": [
      "Age missing -> median",
      "Embarked missing -> mode",
      "Sex -> binary encoding",
      "Embarked -> one-hot",
      "Standardization using train mean/std",
      "Split train/val/test = 70/15/15"
    ],
    "metrics": [
      "accuracy",
      "precision",
      "recall",
      "f1"
    ],
    "name": "Titanic",
    "seed": 1,
    "is_backup": true,
    "primary_method": "MLP"
  }
}